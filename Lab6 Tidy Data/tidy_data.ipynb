{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/crowdlearning-etic.png\" alt=\"Logo ETIC\" align=\"right\">\n",
    "<br>\n",
    "<h1><font color=\"#004D7F\" size=6>Tidy Data</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Antonio Jesús Gil</font><br>\n",
    "<font color=\"#004D7F\" size=3>Introducción a la Ciencia de Datos</font><br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "* [2. Tidy Data](#section2)\n",
    "* [3. Problema 1](#sectionp1)\n",
    "* [4. Problema 2](#sectionp2)\n",
    "* [5. Problema 3](#sectionp3)\n",
    "* [6. Problema 4](#sectionp4)\n",
    "* [7. Problema 5](#sectionp5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "---\n",
    "\n",
    "\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos visto que un formato tabular o relacional es quizás el más organizado o rico en detalles para almacenar nuestros datos. No obstante este formato no garantiza una representación óptima de los datos de cara a minimizar espacio, flexibilidad y facilidad de manipulación.\n",
    "\n",
    "En un proceso de análisis de datos dedicamos en torno al 80% del tiempo a __limpiar__ los datos (__Data Cleaning__), y aunque en la mayoría de los casos esto incluye una gran cantidad de trabajo transformando nuestros datos o extrayendo información a partir de formatos no estructurados, también se realizan muchas tareas procesando y limpiando datos en formatos estructurados.\n",
    "\n",
    "El trabajo de un analista o de un científico de datos es el análisis de la información después de haberse recopilado por lo que debemos adaptar su formato para que sea lo más estándar posible y compatible con las herramientas a utilizar. _Puede que el formato original de los datos_ seá más adecuando para su recopilación o directamente sea erróneo.\n",
    "\n",
    "\n",
    "## <font color=\"#004D7F\"> Tidy Data\n",
    "\n",
    "Tidy data es un esfuerzo por crear un estándar en el formato de los datos estructurados de cara a desarrollar __técnicas y tecnologías__ estandarizadas a su vez para manipulación y análisis de datos. Data la enorme cantidad de herramientas disponibles en la comunidad muchas veces acabamos dedicando demasiado tiempo a adaptar la salida de una tecnología concreta para poder utilizarla como entrada de otra. Unas pautas de modelado estandarizadas permitirán que la interfaz de nuevas herramientas se unifique.\n",
    "\n",
    "Además el modelo relacional propuesto por Codd está planteado en un lenguaje alejado del lenguaje __estadístico__, Tidy Data puede verse como una reinterpretación del modelo relacional en términos naturales y más útiles para el análisis de datos y la estadística. Esto implica también que algunas de las pautas que impone el estandar ayuden también a optimizar la representación de la información no solo a nivel instrumental sino a nivel estadístico.\n",
    "\n",
    "\n",
    "### <font color=\"#004D7F\"> Origen\n",
    "\n",
    "El estándar Tidy data fue propuesto por [Hadley Wickham](http://hadley.nz), un estadístico que ha trabajado tanto en el campo académico como en el empresarial (Director científico en Rstudio). El trabajo original contextualiza el estándar dentro de las herramientas del lenguaje de programación R, no obstante los principios básicos se explican de manera genérica para cualquier conjunto de datos, lo que ha permitido extrapolar sus resultados al conjunto de herramientas para la ciencia de Datos.\n",
    "\n",
    "El paper puede encontrarse públicamente y es una lectura básica para cualquier profesional de este campo.\n",
    "\n",
    "> <i class=\"fa fa-book\" style=\"color:#113D68\"></i> [2014 Hadley Wickham. Tidy Data. Journal of Statistical Software](http://vita.had.co.nz/papers/tidy-data.html)\n",
    "\n",
    "\n",
    "### <font color=\"#004D7F\"> Definición\n",
    "\n",
    "El estándar __tidy data__ se basa en tres reglas sencillas:\n",
    "\n",
    "1. Cada __variable__ es representada por una __columna__.\n",
    "2. Cada __observación__ representada por una __fila__.\n",
    "3. Cada __unidad observacional__ es representada por una __tabla__.\n",
    "\n",
    "Cualquier dataset que no este organizado de esta manera se denomina __messy data__ o datos desorganizados.\n",
    "\n",
    "\n",
    "### <font color=\"#004D7F\"> Ejemplo\n",
    "\n",
    "El siguiente ejemplo muestra un como estructurar un mismo problema de distintas formas, una de ellas tidy.\n",
    "\n",
    "El problema consta de tres variables:\n",
    "\n",
    "- `patient` con tres posibles valores (John, Mary, Jane)\n",
    "- `treatment` con dos posibles valores\n",
    "- `result` con 5 valores más la posibilidad de estar perdido (-, 16, 3, 2, 11, 1)\n",
    "\n",
    "Se han realizado una experimentación cruzada en la que se le ha aplicado un tratamiento a cada paciente y se ha medido el resultado. Los datos podrían haberse recopilado de la siguiente manera durante el estudio original:\n",
    "\n",
    "<table class=\"table table-hover\">\n",
    "    <thead>\n",
    "        <tr> <th></th> <th>treatmenta</th> <th>treatmentb</th> </tr> \n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> <td>John</td> <td>-</td> <td>2</td> </tr>\n",
    "        <tr> <td>Jane</td> <td>16</td> <td>11</td> </tr>\n",
    "        <tr> <td>Mary</td> <td>3</td> <td>1</td> </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "En otro contexto los datos podrían haberse recopilado por tratamiento\n",
    "\n",
    "<table class=\"table table-hover\">\n",
    "    <thead>\n",
    "        <tr> <th></th> <th>John</th> <th>Jane</th> <th>Mary</th> </tr> \n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> <td>treatmenta</td> <td>-</td> <td>16</td> <td>3</td> </tr>\n",
    "        <tr> <td>treatmentb</td> <td>2</td> <td>11</td> <td>1</td> </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "Estos formatos no nos permiten identificar los elementos experimentales, no obstante si nos ceñimos al estándar tidy el resultado es mucho más representativo.\n",
    "\n",
    "<table class=\"table table-hover\">\n",
    "    <thead>\n",
    "        <tr> <th>name</th> <th>treatment</th> <th>result</th> </tr> \n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr> <td>John</td> <td>a</td> <td>-</td> </tr>\n",
    "        <tr> <td>Jane</td> <td>a</td> <td>16</td> </tr>\n",
    "        <tr> <td>Mary</td> <td>a</td> <td>3</td> </tr>\n",
    "        <tr> <td>John</td> <td>b</td> <td>2</td> </tr>\n",
    "        <tr> <td>Jane</td> <td>b</td> <td>11</td> </tr>\n",
    "        <tr> <td>Mary</td> <td>b</td> <td>1</td> </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "El formato tidy nos permite determinar claramente que columnas son observaciones y cuales variables, relaciones funcionales entre ellas, restricciones y una única forma de extraer toda la información del dataset. Además permite identificar mejor cualquier anomalía, como por ejemplo los casos perdidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "# <font color=\"#004D7F\"> 2. Data Tidying and Cleaning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta práctica plantearemos los mismos supuestos que en el paper original de tidy data y trataremos de obtener el formato tidy utilizando las herramientas de python a nuestra disposición como `pandas` y `numpy`.\n",
    "\n",
    "No hay una solución única a cada problema ni una receta básica que podamos aplicar, pero si podemos identificar patrones comunes en cada dataset. Como cita Wickham en el paper original:\n",
    "\n",
    "> _Happy families are all alike; every unhappy family is unhappy in its own way_\n",
    "\n",
    "> _Leo Tolstoy_\n",
    "\n",
    "\n",
    "\n",
    "## <font color=\"#004D7F\"> Objetivos\n",
    "\n",
    "### <font color=\"#004D7F\"> Obtener el formato Tidy de los datos\n",
    "\n",
    "Todos los datasets originales (__raw__) se encuentran en formatos no ordenados y es necesario transformarlos para poder generar su version tidy.\n",
    "\n",
    "\n",
    "### <font color=\"#004D7F\"> Utilización de técnicas reproducibles y entender las transformaciones de manera \"agnóstica\" al lenguaje\n",
    "\n",
    "En el paper original de tidy data se defininen las operaciones de manera general, explicado las transformaciones sobre los datos de manera independiente o agnóstica a cualquier lenguaje antes de aplicar instrucciones propias de R. Es muy importante no obsesionarse con los detalles instrumentales de herramientas particulares como `pandas` y quedarse con las estrategias y técnicas a nivel teórico.\n",
    "\n",
    "Intentaremos utilizar funciones de alto nivel y escribir un código lo más reproducible posible, cercado casi al lenguaje natural, que permita entender y reproducir el proceso de transformación con solo leerlo.\n",
    "\n",
    "Un buen recurso para ir absorbiendo el vocabulario es la siguiente referencia de `pandas` enfocada más al lenguaje de la Ciencia de Datos que a la propia librería.\n",
    "\n",
    "> <i class=\"fa fa-book\" style=\"color:#113D68\"></i> [Pandas Data Wrangling Cheatsheet](http://cs.umw.edu/~stephen/cpsc219/Pandas_Cheat_Sheet.pdf)\n",
    "\n",
    "Resulta curioso contrastar el documento anterior con la [fuente original](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf), la misma hoja orientada al lenguaje `R`, donde la __semántica__ es la misma y solo cambia la __sintaxis__.\n",
    "\n",
    "\n",
    "### <font color=\"#004D7F\"> Limpieza adicional de los datos\n",
    "\n",
    "Además de obtener el formato tidy, vamos a realizar una serie de transformaciones sobre los datos que limpien aun más el formato y obtengan un dataset cómodo y representativo de cara a hacer exploración de datos y modelado.\n",
    "\n",
    "1. El nombre de las variables cumplirá las restriciones de python en cuanto caracteres, empezará en Mayuscula y utilizara CamelCase.\n",
    "2. Las variables estarán ordenadas de manera lógica a la unidad observacional representada. En primer lugar colocaremos variables experimentales y en segundo lugar observaciones, además intentaremos preservar órdenes jerárquicos y colocaremos factores o categorias antes de variables numéricas.\n",
    "3. Los casos del dataset se ordenarán conforme a patrones temporales o alfabéticos en función de sus variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#004D7F\"> Dependencias\n",
    "\n",
    "Antes de comenzar cargaremos las dependencias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#004D7F\"> Conjuntos de datos\n",
    "\n",
    "Se proporcionan los siguientes conjuntos de datos en la carpeta `./data`, en sus versiones desorganizadas y tidy, durante las siguientes secciones estudiaremos los diferentes problemas que plantean.\n",
    "\n",
    "* `pew-raw.csv`\n",
    "* `pew-tidy.csv`\n",
    "* `billboard-raw.csv`\n",
    "* `billboard-tidy.csv`\n",
    "* `tb-raw.csv`\n",
    "* `tb-tidy.csv`\n",
    "* `2014-baby-names-raw.csv`\n",
    "* `2015-baby-names-raw.csv`\n",
    "* `baby-names-tidy.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# <font color=\"#004D7F\"> Problema 1: Cabeceras de columnas como valores\n",
    "\n",
    "Este es uno de los problemas más comunes en datasets desorganizados. Si bien es un formato comprimido que puede resultar útil para su almacenamiento o introducción manual, resulta inconveniente para su análisis ya que no todos los datos están almacenados como valores.\n",
    "\n",
    "El dataset de ejemplo `pew` explora la relación entre los ingresos y la religión de diversos ciudadanos americanos consultados por un centro de investigación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pew = pd.read_csv(\"./data/pew-raw.csv\")\n",
    "df_pew.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset tiene las siguientes variables `religion`, `income` y `freqcuency`. No obstante la variable `income` se encuentra representada por las distintas columnas. La versión tidy de este dataset utilizaría una única columna para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pew_tidy = pd.read_csv(\"./data/pew-tidy.csv\")\n",
    "df_pew_tidy.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la versión tidy de este dataset necesitamos realizar las siguientes operaciones:\n",
    "* Una operación de `reshape` para transformar las columnas que representan un valor (_colvars_) a una sola columna, mapeando el dato correspondiente de la tabla y manteniendo el valor de la religión fijo para dicho caso. En pandas esta operación se denomina `melt`.\n",
    "* En este caso el dataset se ha ordenado por la variable religión, que debe aparecer la primera por ser el campo de agrupación.\n",
    "* Las variables deben utilizar CamelCase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pew_tidy_ex = df_pew.melt(id_vars = [\"religion\"], var_name = 'Income', value_name='Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pew_tidy_ex = df_pew_tidy_ex.sort_values(\"religion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pew_tidy_ex = df_pew_tidy_ex.rename(columns = {'religion':'Religion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La lectura y compresion de las transformaciones no son muy legibles por eso las librerias datasicentist disponen\n",
    "# de pipes para secuenciar. Pipeline\n",
    "df_pew2_tidy_ex = (df_pew\n",
    "                  .melt(id_vars = [\"religion\"], var_name = 'Income', value_name = 'Freq')\n",
    "                  .sort_values(\"religion\")\n",
    "                  .rename(columns = {'religion':'Religion'})\n",
    "                  .reset_index() # Hacemos un reset de indices\n",
    "                   .drop(\"index\", axis = 1) # Borramos la columna index anterior\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pew_tidy_ex.head(8)\n",
    "#df_pew2_tidy_ex.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# <font color=\"#004D7F\"> Problema 2: Cabeceras de columnas como valores, variables redundantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este problema es similar al anterior pero añade una capa de complejidad adicional, ya que los valores almacenados en las columnas están codificados como string cuando podrían ser de tipo numérico.\n",
    "\n",
    "El dataset `billboard` contiene un estudio sobre el ranking que mantiene una canción que entra en la lista de las 100 más populares cada nueva semana a partir de la que entró.\n",
    "\n",
    "En la representación original tenemos una serie de variables para identificar cada canción como `year`, `artist.inverted`, `track`, `time`, `genre` y una serie de variables observacionales que representan los datos medidos, donde `date.entered` corresponde con la fecha en la que entró la canción en el ranking y 100 variables `x[0-100].week` que representan el ranking para esa semana concreta. En el caso de que la canción saliese antes de la lista el valor para esa columna es `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill = pd.read_csv(\"./data//billboard-raw.csv\")\n",
    "df_bill.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La versión tidy de este dataset muestra una organización mucho más razonable. La fecha y las columnas representando cada semana se han fusionado para representar la fecha de la medición asignandole a dicha entrada el ranking concreto para el resto de datos de la canción. En el caso de que la canción saliese de la lista se ha eliminado dicha observación, ya que el hecho de que no se encuentre en el dataset representa la existencia de un dato perdido __implícito__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_tidy = pd.read_csv(\"./data/billboard-tidy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_tidy.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para transformar el dataset a un formato tidy necesitamos realizar los siguientes pasos:\n",
    "\n",
    "- Realizar una operación de `reshaping`(`melt`) para transformar las colvars que representan cada semana en una sola columna, manteniendo los identificadores de cada canción.\n",
    "- Transformar la variable week resultante en una columna numérica, extrayendo el valor de la semana del string correspondiente. Utilizando expresiones regulares por ejemplo. (Será el Ranking)\n",
    "- Eliminar los casos perdidos\n",
    "- Computar la nueva variable fecha `Date` utilizando para ello la fecha de inicio a la que sumamos la semana actual.\n",
    "- Renombrar y reorganizar las variables para que utilicen CamelCase y se ordenen de manera lógica\n",
    "- Ordenar el dataset por año y canción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "# Extraer el número de la semana\n",
    "def extractWeek(code):\n",
    "\n",
    "    if match:\n",
    "        return int(match.group(1)) # Transformar a entero haciendo un cast\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Funcion para sumar las fechas (semanas). La funcion recibe las columnas enteras\n",
    "def computeDate(dates, weeks):\n",
    "    return pd.to_datetime(dates) + pd.to_timedelta(weeks - 1, unit = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar función\n",
    "extractWeek(\"x4th.week\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_tidy_ex = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_tidy_ex.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# <font color=\"#004D7F\"> Problema 3: Múltiples variables almacenadas en las columnas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este problema es una generalización del anterior en el que las columnas que representan valores de una variable o `colvars` están codificadas para mezclar varias variables al mismo tiempo.\n",
    "\n",
    "El dataset `TB`es un estudio médico de la incidencia de la tuberculosis en distintos grupos demográficos por paises. Las variables que contiene son `country`, `year`, `age`, `sex` y `cases`. No obstante el formato original codifica los disintos grupos de género y edad como columnas para contar los casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tb = pd.read_csv(\"./data/tb-raw.csv\")\n",
    "df_tb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el dataset tidy extrae ambas variables género y edad de las distintas colvars para obtener observaciones únicas por cada grupo poblacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tb_tidy = pd.read_csv(\"./data/tb-tidy.csv\")\n",
    "df_tb_tidy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener el dataset tidy hemos de realizar un proceso muy similar al del problema anterior pero generalizando la extracción de valores para varias variables:\n",
    "\n",
    "- Realizamos un reshaping `melt` para transformar las colvars en una columna `sex_and_age`\n",
    "- Eliminamos los valores perdidos\n",
    "- Transformamos la nueva columna `sex_and_age` en dos columnas `sex` y `age`\n",
    "- Renombramos las variables y nos aseguramos que utilizan CamelCase y ordenamos según corresponda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones auxiliares\n",
    "# Extraer sexo y edad\n",
    "def extractSexnAge(code):\n",
    "    pattern = \"(\\S)(\\d+)(\\d{2})\"\n",
    "    match = re.search(pattern, code)\n",
    "    if match:\n",
    "        sex = match.group(1)\n",
    "        age = \"{}-{}\".format(match.group(2), match.group(3))\n",
    "        return [sex, age]\n",
    "    else:\n",
    "        return [np.NaN, np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tb_tidy_ex = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tb_tidy_ex.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# <font color=\"#004D7F\"> Problema 4: Múltiples tipos en la misma tabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este problema conocido como normalización identifica datos que se encuentran potencialmente repetidos al incluir todas las variables de identificación de la unidad observacional en otra unidad obersavacional que represente un conjunto de mediciones.\n",
    "\n",
    "Por ejemplo en el dataset `billboard` anterior estamos incluyendo toda la información referente a la canción en cada entrada para identificar el rango en una semana concreta. Esto supone una gran cantidad de información repetida. La representación ideal normalizará este modelo en dos tablas, una para la información de la canción y otra para las mediciones de ranking. Relacionando las dos con una variable de identificación (modelo relacional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_norm_tracks = pd.read_csv(\"./data/billboard-norm-tracks.csv\")\n",
    "df_bill_norm_ranks = pd.read_csv(\"./data/billboard-norm-ranks.csv\")\n",
    "\n",
    "display(df_bill_norm_tracks.head(8))\n",
    "display(df_bill_norm_ranks.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la representación normalizada de este conjunto de datos debemos realizar los siguientes pasos:\n",
    "\n",
    "Para crear la tabla `tracks`:\n",
    "\n",
    "- Eliminar las columnas `Date` y `Ranks` y eliminar todas las filas duplicadas resultantes.\n",
    "- Crear una nueva columna `Id` que sea un identificador con un valor único para cada caso\n",
    "- Reordenar y renombrar si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_norm_tracks_ex = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_bill_norm_tracks_ex.head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear la tabla `ranks`:\n",
    "\n",
    "- A partir de la tabla original, añadir la columna `Id` para cada caso (debe identificar correctamente la canción conforme a la tabla `tracks`). Para esto podemos hacer un `merge` entre la tabla original y la nueva creata `tracks`.\n",
    "- Eliminar, renombrar y reordenar las columnas resultantes si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bill_norm_ranks_ex = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_bill_norm_ranks_ex.head(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <font color=\"#004D7F\"> Problema 5: Un tipo dividido en varias tablas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este último problema es el opuesto al anterior, en el que nuestros datos están divididos en distintas tablas aun representando el mismo modelo y existe información implícita en la representación, por ejemplo en el nombre de las tablas o los ficheros.. \n",
    "\n",
    "Este es el caso del dataset `baby-names`, que contiene un estudio sobre la frecuencia de los nombres que se les ponen a los bebes en USA en distintos años. Este dataset viene en un formato que proporciona un fichero por año, donde el año viene especificado en el nombre del fichero.\n",
    "\n",
    "Este dataset tiene las variables `year`, `rank`, `name`, `frequency` y `sex`, pero la variable year está implícita en los datos (nombre del fichero) y no aparece en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( pd.read_csv(\"./data/2014-baby-names-raw.csv\").head(5) )\n",
    "display( pd.read_csv(\"./data/2015-baby-names-raw.csv\").head(5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La versión tidy agregaría las distintas tablas y capturaría esta información del nombre de los ficheros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display( pd.read_csv(\"./data/baby-names-tidy.csv\").head(5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractYear(name):\n",
    "    pattern = \"^(\\d{4})\"\n",
    "    match = re.search(pattern, name)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def readDfByYear(path, name):\n",
    "    year = extractYear(name)\n",
    "    return (pd.read_csv(\"{}/{}\".format(path, name))\n",
    "              .assign(Year = year)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la representación tidy de este conjunto de datos debemos realizar los siguientes pasos:\n",
    "- Cargar cada fichero en un DataFrame diferente en `pandas` capturando en una lista por ejemplo el nombre del fichero.\n",
    "- Utilizar expresiones regulares para extraer el año del nombre del fichero.\n",
    "- Para cada DataFrame añadir una columna `Year` indicando el año correspondiente.\n",
    "- Concatenar los datasets.\n",
    "- Renombrar y reordenar si es necesario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baby_tidy_ex = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baby_tidy_ex.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
